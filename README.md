# Segmenta√ß√£o de Objetos em Ambientes Naturais (Dataset CamVid)

Este reposit√≥rio cont√©m o projeto final da **Equipe 5**, desenvolvido para o programa **Atl√¢ntico Avanti**. O objetivo deste projeto √© treinar e avaliar um modelo de Deep Learning (U-Net) para a tarefa de segmenta√ß√£o sem√¢ntica em cenas de tr√¢nsito, utilizando o dataset CamVid.

A segmenta√ß√£o sem√¢ntica classifica cada pixel de uma imagem em uma categoria pr√©-definida (ex: Carro, Estrada, Pedestre, C√©u), uma tarefa crucial para ve√≠culos aut√¥nomos e an√°lise de cenas urbanas.




## üìã Tabela de Conte√∫dos
1.  [Sobre o Dataset (CamVid)](#-sobre-o-dataset-camvid)
2.  [Metodologia](#-metodologia)
    * [Arquitetura do Modelo (U-Net)](#arquitetura-do-modelo-u-net)
    * [Transfer Learning (ResNet-50)](#transfer-learning-resnet-50)
    * [Aumento de Dados](#aumento-de-dados)
3.  [Tecnologias Utilizadas](#-tecnologias-utilizadas)
4.  [Como Executar](#-como-executar)
5.  [Resultados](#-resultados)
    * [Curvas de Treinamento](#curvas-de-treinamento)
    * [M√©tricas de Teste](#m√©tricas-de-teste)
    * [Matriz de Confus√£o](#matriz-de-confus√£o)
    * [An√°lise Qualitativa](#an√°lise-qualitativa)
6.  [Conclus√µes e Trabalhos Futuros](#-conclus√µes-e-trabalhos-futuros)
7.  [Equipe](#-equipe)
8.  [Refer√™ncias](#-refer√™ncias)

---

## üíæ Sobre o Dataset (CamVid)

Utilizamos o **CamVid (Cambridge-Driving Labeled Video Database)**, um dataset popular para segmenta√ß√£o sem√¢ntica focado em cenas de tr√¢nsito.

Ap√≥s a An√°lise Explorat√≥ria de Dados (EDA), o dataset foi dividido da seguinte forma:
* **Treino:** 369 imagens e 369 m√°scaras
* **Valida√ß√£o:** 100 imagens e 100 m√°scaras
* **Teste:** 232 imagens e 232 m√°scaras

A an√°lise (slides 6-8) confirmou que todas as imagens s√£o `.png` com dimens√£o de 960x720 pixels e que as classes s√£o **altamente desbalanceadas**. Classes como `Road` e `Sky` s√£o muito frequentes, enquanto `Bicyclist` e `Animal` s√£o raras. Esta descoberta foi crucial para a escolha da nossa fun√ß√£o de perda (Loss).

---

## üî¨ Metodologia

O projeto foi estruturado em tr√™s fases: 1) Aquisi√ß√£o e An√°lise de Dados, 2) Pr√©-processamento e Aumento de Dados, e 3) Modelagem e Avalia√ß√£o.

### Arquitetura do Modelo (U-Net)

A arquitetura escolhida foi a **U-Net**, famosa por sua efic√°cia em tarefas de segmenta√ß√£o biom√©dica e, posteriormente, em cenas urbanas.
* **Encoder (Codificador):** Analisa a imagem, extrai caracter√≠sticas e reduz a resolu√ß√£o.
* **Decoder (Decodificador):** Reconstr√≥i a imagem, aumentando a resolu√ß√£o para criar a m√°scara de segmenta√ß√£o.
* **Skip Connections:** Conectam o Encoder ao Decoder para preservar detalhes finos e informa√ß√µes de localiza√ß√£o precisas.

### Transfer Learning (ResNet-50)

Para acelerar o treinamento e melhorar a precis√£o, utilizamos **Transfer Learning**.
* Usamos um encoder **ResNet-50**, pr√©-treinado no gigantesco banco de dados **ImageNet**.
* Isso significa que nosso modelo j√° come√ßa o treinamento com uma "intelig√™ncia visual" avan√ßada, capaz de reconhecer caracter√≠sticas b√°sicas de objetos.

### Aumento de Dados

Para evitar *overfitting* e tornar o modelo mais robusto a diferentes condi√ß√µes (luz, √¢ngulo), utilizamos a biblioteca `albumentations` para aplicar transforma√ß√µes aleat√≥rias apenas nos dados de treino:
* `A.HorizontalFlip`: Invers√£o horizontal.
* `A.ColorJitter`: Altera√ß√µes de cor e brilho.
* `A.GaussianBlur`: Desfoque.
* E outras (Rota√ß√£o, `RandomBrightnessContrast`, etc.)

---

## üöÄ Tecnologias Utilizadas

Este projeto foi constru√≠do inteiramente em **Python**. As principais bibliotecas e frameworks utilizados s√£o:

* **Framework Principal:** PyTorch
* **Biblioteca de Segmenta√ß√£o:** `segmentation-models-pytorch (smp)`
* **An√°lise de Dados:** NumPy e Pandas
* **Manipula√ß√£o de Imagem:** OpenCV e Pillow
* **Aumento de Dados:** Albumentations
* **Visualiza√ß√£o:** Matplotlib e Seaborn

---

## ‚öôÔ∏è Como Executar

O projeto est√° contido em um notebook (`.ipynb`) que deve ser executado no Google Colab para aproveitar a acelera√ß√£o de GPU.

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [(https://github.com/eloisamarin/projeto-segmentacao-camvid)]((https://github.com/eloisamarin/projeto-segmentacao-camvid))
    ```
2.  **Abra o Notebook no Google Colab:**
    * Fa√ßa o upload do arquivo `seu_notebook.ipynb` para o Colab.
3.  **Habilite a GPU:**
    * No menu, v√° em `Ambiente de execu√ß√£o` -> `Alterar o tipo de ambiente de execu√ß√£o` -> `Acelerador de hardware` -> `GPU`.
4.  **Instale as Depend√™ncias:**
    * A primeira c√©lula do notebook cont√©m os comandos `!pip install` necess√°rios.
5.  **Execute as C√©lulas:**
    * Execute todas as c√©lulas em ordem. O notebook far√° o download do dataset (via Kaggle API), far√° a an√°lise, definir√° o modelo, treinar√° e, ao final, exibir√° os resultados da avalia√ß√£o.

---

## üìä Resultados

O modelo foi treinado por 25 √©pocas usando o otimizador **Adam**, **ReduceLROnPlateau** (Scheduler) e **EarlyStopping** para salvar o melhor modelo e evitar *overfitting*. As m√©tricas de avalia√ß√£o principais foram **IoU (Intersection over Union)**, **Coeficiente Dice** e **Acur√°cia**.

### Curvas de Treinamento

O gr√°fico de perdas (Loss) demonstra a converg√™ncia bem-sucedida do modelo. A perda de treino (`Train Loss`) e a perda de valida√ß√£o (`Val Loss`) diminuem de forma est√°vel, indicando que o modelo aprendeu sem *overfitting* significativo.
*(Baseado no gr√°fico de Loss do slide 17)*



## üîÆ Conclus√µes e Trabalhos Futuros

### Conclus√µes
O estudo validou com sucesso o uso da arquitetura U-Net com um encoder ResNet-50 pr√©-treinado para segmenta√ß√£o sem√¢ntica no CamVid. A valida√ß√£o de um pipeline de *Transfer Learning* e uma an√°lise (EDA) detalhada foram contribui√ß√µes chave, guiando a escolha do modelo e da fun√ß√£o de perda combinada (Dice + Focal) para lidar com o desbalanceamento de classes.

### Possibilidades de Novos Estudos
* **Testar Encoders Mais Modernos:** Substituir o `ENCODER` por `EfficientNet-B5`, que j√° est√° previsto no c√≥digo.
* **Ajuste de Hiperpar√¢metros:** Otimizar o `LAMBDA` (peso entre Dice e Focal) ou a Taxa de Aprendizado (`LR`).
* **Aumento de Dados Agressivo:** Aplicar t√©cnicas mais avan√ßadas para melhorar o desempenho em classes raras.

---

## üë• Equipe

* **Eloisa Marin da Silva Pessoa**
* **Lucas dos Santos Fileto**
* **Victor Leandro da Silva**
